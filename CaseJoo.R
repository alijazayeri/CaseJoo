# importing some libraries
library(dplyr)
library(stringi)
library(tidyr)
library(rio)        # --> I use this library for importing, not required

library(easyPubMed) # --> library used for PubMed data retrieval
library(XML)        # --> this library and the next one is used for parsing XML data retrieved by easyPubMed library
library(xml2)
library(quanteda)   # --> library used for text processing

library(ggplot2)    # --> just for ploting (not necessarily required)
#_____________________________________________________________________

# This function generates a PubMed search query based on the list of keywords provided by the user
# They keywords can be generally phenotypes of the patient, clinical manifestation or any clinical presentation related to the patient's disease
# Example:
#       sample_keys <- c('Ichthyosis','Palmoplantar hyperkeratosis','Anhidrosis','Erythroderma','Ectropion')
#       sample_query <- generate_query(sample_keys)
generate_query <- function(keywords){
    # An empty string to be completed with keywords
    query_string <- ""
    # This loop iterates over the keywords and creates the search query similar to PubMed queries
    for (kw_ix in 1:length(keywords)){
        kw <- keywords[kw_ix]
        if (kw_ix==1){
            query_string <- paste('(',kw,'[Title/Abstract])',sep = '')}
        else{
            query_string <- paste('(',query_string,' OR ',kw,'[Title/Abstract])',sep = '')
        }
    }
    query_string <- paste(query_string,' AND gene_name[Title/Abstract]',sep = '')
    return(query_string)
}


# This returns a data frame composed of potential relevant genes and number of papers in the PubMed related to these genes
# This function gets a list of (all) unique genes provided by the user
# and the query generated by the generate_query function (refer to sample_query in the comment above)
# Example:
#       sample_genes <- c('ABCC1','DPYD', 'BCR', 'CDKN1C','CASQ2' ,'CYP1B1', 'ELOVL4','ITGA10' ,'KRT10','JTB' ,'KRT4','MRC1' ,'NIPA1', 'ORAI1','FBXL3' ,'PSORS1C1','RGL3' ,'RAD50','DDR1' ,'SQSTM1')
#       sample_search <- retrieve_genes(sample_genes,sample_query)
retrieve_genes <- function(uniqGenes, query){
    print(paste('total number of genes is:',length(uniqGenes)))
    pubmedDf <- data.frame()
    gcnt <- 0
    gcnt2 <- 0
    for (i in uniqGenes){
        gcnt2 <- gcnt2 + 1
        print(paste('Working on gene number: ',gcnt2,', which is:',i,sep = ''))
        # Customizing the query based on the gene
        gene_query <- gsub('gene_name',i, query)
        # Downloading data from PubMed based on the search query
        out.A <- batch_pubmed_download(pubmed_query_string = gene_query, 
                                       format = "xml", 
                                       batch_size = 5000,
                                       dest_file_prefix = "temp_file")
        # A data frame is created for each paper which includes both the gene name and at least one of the keywords 
        if (!is.null(out.A[1])){
            new_PM_df <- table_articles_byAuth(pubmed_data =out.A[1] , included_authors = "first", max_chars = 0)
            if (nrow(new_PM_df)>0){
                new_PM_df$gene <- i
                if (gcnt == 0){
                    pubmedDf <- new_PM_df[,c("pmid","title" ,"year","gene")]
                    gcnt <- gcnt + 1}
                else {
                    pubmedDf <- rbind(pubmedDf,new_PM_df[,c("pmid","title","year","gene")])
                    gcnt <- gcnt + 1}
            }
        }
    }
    # The data frame is transformed to include the name of genes and the number of their corresponding papers
    pubmedDf <- pubmedDf %>% group_by(gene) %>% summarise(cnt = n_distinct(title))
    return(as.data.frame(pubmedDf))
}



# Most of the code inside the similarityCalc function comes from:
# https://github.com/datasciencedojo/IntroToTextAnalyticsWithR (Thanks so much to them!)
# This function is called from another function (prioritize_genes) for computing the similarity.
# between the abstracts and keywords
# The user doesn't need to call this function directly!
similarityCalc <- function(abst,keywords){
    docs <- data.frame(id = c(1), text = c(paste(keywords,collapse = ' '),abst), Text1 = c('a','b'))
    # Tokenize abstract and keywords representing the patients' condition.
    docs.tokens <- tokens(as.character(docs$text), what = "word", 
                           remove_numbers = TRUE, remove_punct = TRUE,
                           remove_symbols = TRUE, remove_hyphens = TRUE, remove_separators = TRUE)
    
    # Lower case the tokens.
    docs.tokens <- tokens_tolower(docs.tokens)
    
    # Use quanteda's built-in stopword list for English.
    docs.tokens <- tokens_select(docs.tokens, stopwords(), selection = "remove")
    
    # Perform stemming on the tokens.
    docs.tokens <- tokens_wordstem(docs.tokens, language = "english")

    # Create our first bag-of-words model.
    docs.tokens.dfm <- dfm(docs.tokens, tolower = FALSE)
    
    # Transform to a matrix.
    docs.tokens.matrix <- as.matrix(docs.tokens.dfm)
    
    # Our function for calculating relative term frequency (TF)
    term.frequency <- function(row) {
        row / sum(row)
    }
    
    # Our function for calculating inverse document frequency (IDF)
    inverse.doc.freq <- function(col) {
        corpus.size <- length(col)
        doc.count <- length(which(col > 0))
        if (doc.count > 0){
            return(1+log10(corpus.size / doc.count))
        }
        else{
            return(1)
        }
    }
    
    # Our function for calculating TF-IDF.
    tf.idf <- function(x, idf) {
        x * idf
    }
    
    # First step, normalize all documents via TF.
    docs.tokens.df <- apply(docs.tokens.matrix, 1, term.frequency)
    
    # Second step, calculate the IDF vector that we will use 
    docs.tokens.idf <- apply(docs.tokens.matrix, 2, inverse.doc.freq)
    
    # Lastly, calculate TF-IDF.
    docs.tokens.tfidf <-  apply(docs.tokens.df, 2, tf.idf, idf = docs.tokens.idf)
    
    # Transpose the matrix
    docs.tokens.tfidf <- t(docs.tokens.tfidf)
    a <- docs.tokens.tfidf[1,]
    b <- docs.tokens.tfidf[2,]
    
    # Calculating the similarity between the abstract and the keywords
    similarity <- ( sum(a*b) / ( sqrt(sum(a * a)) * sqrt(sum(b * b)) ) )
    return(similarity)
}

# This function computes the cosine similarity between keywords provided by the user as a representation of clinical manifestation of the patient
# and the abstract of each paper for each gene the list of genes returned by the retreive_genes function
# Then, the function computes the mean of similarities for each gene, and finally return a list composed of two data frame
# data frame 1: it includes one row for each paper returned, and two columns:
#                       gene: shows the name of the gene corresponding to that row 
#                       similarity_value: shows the cosine similarity of the corresponding paper with keywords
# data frame 2: it groups the data frame 1 based on gene names and aggregates the number of papers returned and the mean of the 
#               similarities for each gene                
# Example:
#       potential_gene <- sample_search$gene  # <- Here, potential_gene refers to the gene returned by retrieve_genes function
#       sample_similarity <- prioritize_genes(potential_gene,sample_query,sample_keys)
prioritize_genes <- function(potential_gene,query,keywords){
    simDf <- data.frame()
    for(j in potential_gene){
        gene_query <- gsub('gene_name',j, query)
        first_PM_records <- get_pubmed_ids(gene_query)   # submit the query to PubMed
        totalXML <- fetch_pubmed_data(first_PM_records) 
        
        rootnode <- xmlRoot(xmlTreeParse(totalXML, useInternalNodes = TRUE))
        
        xml_cap <- capture.output(rootnode)
        val_df <- as.data.frame(xml_cap[which(grepl('AbstractText|PMID',xml_cap))])
        names(val_df)[1] <- 'abst'
        val_df_sep <- val_df %>% separate(abst, into = paste0('AbstractText', 1:4), sep = '[><]')
        val_df_sep$rowtype <- NA
        val_df_sep$AbstractText1 <- seq.int(nrow(val_df_sep))
        val_df_sep$rowtype[which(grepl('PMID',val_df_sep$AbstractText4))] <- val_df_sep$AbstractText1[which(grepl('PMID',val_df_sep$AbstractText4))]
        
        val_df_sep <- val_df_sep %>% fill(rowtype) 
        
        val_df_sep_agg <- aggregate(val_df_sep$AbstractText3, list(val_df_sep$rowtype), paste, collapse=" ")
        val_df_sep_agg_filtered <- val_df_sep_agg[which(nchar(val_df_sep_agg$x)>10),'x']
        
        simlist <- c()
        for (i in val_df_sep_agg_filtered){
            simDf <- rbind(simDf,data.frame(t(c('X1' = j, 'X2' = similarityCalc(i,keywords = keywords)))))
        }
        Sys.sleep(1)
    }
    simDf <- simDf[-4,]
    simDf$X2 <- as.numeric(as.character(simDf$X2))
    meanSim <- simDf %>%
        group_by(X1) %>%
        summarise(count=n(),similarity_mean = mean(X2))
    names(simDf) <- c('gene','similarity_value')
    names(meanSim) <- c('gene','retrieved_abstracts','similarity_mean')
    return(list(sim_values = simDf,sim_means = as.data.frame(meanSim)))
}


# plotting the genes based on their number of abstract returned and the mean of their similarities to the 
# keywords representing the patient's condition
ggplot(sample_similarity[[2]],aes(similarity_mean,retrieved_abstracts,label=gene))+
    geom_point(color = "blue", size = 3)+
    geom_text(aes(label=gene),hjust=-0.1, vjust=-0.1)+
    xlab('Average of similarityies for each gene')+
    ylab('No. of documents retrieved')+
    theme_bw(base_size = 16)+
    scale_x_continuous(limits = c(0, 0.1))+
    scale_y_continuous(limits = c(0, 40))
#____________________________________________________________________________________
